{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e7fe959-0cf8-4011-a98c-99c33f37e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from preprocessing import *\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c7ded38-2e71-4860-95a1-34c6144e6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "DATA_DIR = './data/'\n",
    "PLOTS_DIR = './plots/'\n",
    "\n",
    "X, y = load_dataset(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb9837b-3ca1-42f6-a7b3-6063d3b1cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in train and test set while keeping the \n",
    "# ratio between the target classes (as the data is imbalanced)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=0.7, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n",
    "\n",
    "# split the test set in test and validation set while keeping \n",
    "# the ratio between the target classes\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, \n",
    "                                                train_size=0.5, \n",
    "                                                random_state=42, \n",
    "                                                stratify=y_test)\n",
    "\n",
    "data = [X_train, X_test, X_val]\n",
    "labels = [y_train, y_test, y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1e7028-90eb-4095-bce6-d8abd92d0f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWCUT = 0.5\n",
    "HIGHCUT = 40\n",
    "SAMPLINGRATE = 173.61\n",
    "\n",
    "# define the scaler \n",
    "scaler = scaler(X_train)\n",
    "# define the filter coefficients\n",
    "b, a = butter_bandpass(LOWCUT,HIGHCUT,SAMPLINGRATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44b0475-ee52-4609-9dd9-f6f68771a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = list()\n",
    "processed_labels = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383a56f0-be35-48a6-ac2a-6b035ce670ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the preprocessing pipeline to the different sets\n",
    "for X, y in zip(data, labels):\n",
    "    filtered_X = butter_bandpass_filter(X,b,a)\n",
    "    standardized_X = standardize_data(scaler, filtered_X)\n",
    "    prepared_X, prepared_y = sliding_window(standardized_X, y, 241)\n",
    "    processed_data.append(prepared_X)\n",
    "    processed_labels.append(prepared_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neurodynamics]",
   "language": "python",
   "name": "conda-env-neurodynamics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
